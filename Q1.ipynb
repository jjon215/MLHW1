{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjon215/MLHW1/blob/master/Q1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "L8-uycmOq12g",
        "colab_type": "code",
        "outputId": "393d3d82-8eaf-4d80-bcd7-076c2537121d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2097
        }
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "\n",
        "batch_size = 100\n",
        "expments = 40\n",
        "learn_rate = 0.005\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = (x_train.reshape(x_train.shape[0],x_train.shape[1]*x_train.shape[2]))\n",
        "y_train = (keras.utils.to_categorical(y_train,10))\n",
        "x_test = (x_test.reshape(x_test.shape[0],x_test.shape[1]*x_test.shape[2]))\n",
        "y_tes = y_test\n",
        "y_test = (keras.utils.to_categorical(y_test,10))\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "def initialize_parameters():\n",
        "  W = np.random.randn(10,784)*0.01\n",
        "  b = np.random.randn(10,1)*0.01\n",
        "  return W,b\n",
        "def forward_propagation(W,b,x):\n",
        "  output = np.dot(W,np.transpose(x)) + (b)\n",
        "  output = sigmoid(output)\n",
        "  return output\n",
        "def sigmoid(x): \n",
        "  z = 1/(1+np.exp(-x))\n",
        "  return z\n",
        "\n",
        "def loss_function(y_train,output,batch_size):\n",
        "  loss = np.sum(np.multiply((np.transpose(y_train) - output),(np.transpose(y_train) - output))/2,axis=1,keepdims=True)/batch_size\n",
        "  return loss\n",
        "\n",
        "def backward_propagation(x_train,y_train,output,W,b,learn_rate,batch_size):\n",
        "  \n",
        "  der_loss = -(np.transpose(y_train) - output)\n",
        "  der_sig = sigmoid(output)*(1 - sigmoid(output))\n",
        "  der_z = np.multiply(der_loss,der_sig)\n",
        "  der_W = np.dot(der_z,x_train)\n",
        "  der_b = np.sum(der_z,axis=1,keepdims=True)\n",
        "  W = W - learn_rate*der_W\n",
        "  b = b - learn_rate*der_b\n",
        "  return W,b\n",
        "W,b = initialize_parameters()\n",
        "for j in range(expments):\n",
        "  for i in range(0, x_train.shape[0], batch_size):\n",
        "    output = forward_propagation(W,b,x_train[i:i+batch_size])\n",
        "    W,b = backward_propagation(x_train[i:i+batch_size],y_train[i:i+batch_size],output,W,b,learn_rate,batch_size)\n",
        "  out = forward_propagation(W,b,x_test)\n",
        "  out = np.transpose(out)\n",
        "  out_list = list()\n",
        "  for i in range(10000):\n",
        "    out_list.append(np.argmax(out[i]))\n",
        "  count = 0\n",
        "  for i in range(10000):\n",
        "    if out_list[i] == y_tes[i]:\n",
        "      count += 1\n",
        "  acc = count/100\n",
        "  print(\"Epoch Iteration:\",j)\n",
        "  print(count,\"/10000\")\n",
        "  print(\"Accuracy:\",acc)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch Iteration: 0\n",
            "8950 /10000\n",
            "Accuracy: 89.5\n",
            "Epoch Iteration: 1\n",
            "9041 /10000\n",
            "Accuracy: 90.41\n",
            "Epoch Iteration: 2\n",
            "9081 /10000\n",
            "Accuracy: 90.81\n",
            "Epoch Iteration: 3\n",
            "9101 /10000\n",
            "Accuracy: 91.01\n",
            "Epoch Iteration: 4\n",
            "9110 /10000\n",
            "Accuracy: 91.1\n",
            "Epoch Iteration: 5\n",
            "9124 /10000\n",
            "Accuracy: 91.24\n",
            "Epoch Iteration: 6\n",
            "9127 /10000\n",
            "Accuracy: 91.27\n",
            "Epoch Iteration: 7\n",
            "9136 /10000\n",
            "Accuracy: 91.36\n",
            "Epoch Iteration: 8\n",
            "9144 /10000\n",
            "Accuracy: 91.44\n",
            "Epoch Iteration: 9\n",
            "9144 /10000\n",
            "Accuracy: 91.44\n",
            "Epoch Iteration: 10\n",
            "9147 /10000\n",
            "Accuracy: 91.47\n",
            "Epoch Iteration: 11\n",
            "9155 /10000\n",
            "Accuracy: 91.55\n",
            "Epoch Iteration: 12\n",
            "9156 /10000\n",
            "Accuracy: 91.56\n",
            "Epoch Iteration: 13\n",
            "9156 /10000\n",
            "Accuracy: 91.56\n",
            "Epoch Iteration: 14\n",
            "9156 /10000\n",
            "Accuracy: 91.56\n",
            "Epoch Iteration: 15\n",
            "9156 /10000\n",
            "Accuracy: 91.56\n",
            "Epoch Iteration: 16\n",
            "9157 /10000\n",
            "Accuracy: 91.57\n",
            "Epoch Iteration: 17\n",
            "9155 /10000\n",
            "Accuracy: 91.55\n",
            "Epoch Iteration: 18\n",
            "9159 /10000\n",
            "Accuracy: 91.59\n",
            "Epoch Iteration: 19\n",
            "9158 /10000\n",
            "Accuracy: 91.58\n",
            "Epoch Iteration: 20\n",
            "9158 /10000\n",
            "Accuracy: 91.58\n",
            "Epoch Iteration: 21\n",
            "9159 /10000\n",
            "Accuracy: 91.59\n",
            "Epoch Iteration: 22\n",
            "9160 /10000\n",
            "Accuracy: 91.6\n",
            "Epoch Iteration: 23\n",
            "9161 /10000\n",
            "Accuracy: 91.61\n",
            "Epoch Iteration: 24\n",
            "9161 /10000\n",
            "Accuracy: 91.61\n",
            "Epoch Iteration: 25\n",
            "9163 /10000\n",
            "Accuracy: 91.63\n",
            "Epoch Iteration: 26\n",
            "9163 /10000\n",
            "Accuracy: 91.63\n",
            "Epoch Iteration: 27\n",
            "9167 /10000\n",
            "Accuracy: 91.67\n",
            "Epoch Iteration: 28\n",
            "9167 /10000\n",
            "Accuracy: 91.67\n",
            "Epoch Iteration: 29\n",
            "9168 /10000\n",
            "Accuracy: 91.68\n",
            "Epoch Iteration: 30\n",
            "9171 /10000\n",
            "Accuracy: 91.71\n",
            "Epoch Iteration: 31\n",
            "9173 /10000\n",
            "Accuracy: 91.73\n",
            "Epoch Iteration: 32\n",
            "9174 /10000\n",
            "Accuracy: 91.74\n",
            "Epoch Iteration: 33\n",
            "9177 /10000\n",
            "Accuracy: 91.77\n",
            "Epoch Iteration: 34\n",
            "9176 /10000\n",
            "Accuracy: 91.76\n",
            "Epoch Iteration: 35\n",
            "9177 /10000\n",
            "Accuracy: 91.77\n",
            "Epoch Iteration: 36\n",
            "9177 /10000\n",
            "Accuracy: 91.77\n",
            "Epoch Iteration: 37\n",
            "9178 /10000\n",
            "Accuracy: 91.78\n",
            "Epoch Iteration: 38\n",
            "9179 /10000\n",
            "Accuracy: 91.79\n",
            "Epoch Iteration: 39\n",
            "9181 /10000\n",
            "Accuracy: 91.81\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}